import pandas as pd
import numpy as np
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from lightgbm import LGBMClassifier

def load_and_preprocess(path='./csv/lishiweathers_data.csv'):
    df = pd.read_csv(path)
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
    df['æœˆä»½'] = df['æ—¥æœŸ'].dt.month
    df['å­£èŠ‚'] = df['æœˆä»½'].map({1:1, 2:1, 3:1, 4:2, 5:2, 6:2, 7:3, 8:3, 9:3, 10:4, 11:4, 12:4})
    df['é£åŠ›ç­‰çº§'] = df['é£å‘'].str.extract(r'(\d+)').astype(float)
    df['æ¸©å·®'] = df['æœ€é«˜æ¸©åº¦'] - df['æœ€ä½æ¸©åº¦']
    
    # å¢å¼ºå¤©æ°”ç±»åˆ«åˆå¹¶ç­–ç•¥ï¼ˆç¡®ä¿æœ€å°æ ·æœ¬æ•°ï¼‰
    weather_mapping = {
        'æ™´': 'æ™´',
        'å¤šäº‘': 'å¤šäº‘',
        'é˜´': 'å¤šäº‘',
        'é›¨': 'é›¨',
        'é›·é˜µé›¨': 'é›¨', 
        'é˜µé›¨': 'é›¨',
        'å°é›¨': 'é›¨',
        'ä¸­é›¨': 'é›¨',
        'é›ª': 'é›ª',
        'å¤§é›ª': 'é›ª',
        'å°é›ª': 'é›ª',
        'é›¾': 'å…¶ä»–',  # åˆå¹¶ç¨€æœ‰å¤©æ°”åˆ°å…¶ä»–
        'æ²™å°˜': 'å…¶ä»–'
    }
    df['å¤©æ°”'] = df['å¤©æ°”'].map(weather_mapping).fillna('å…¶ä»–')
    
    # ç¡®ä¿æ¯ä¸ªç±»åˆ«è‡³å°‘æœ‰2ä¸ªæ ·æœ¬
    weather_counts = df['å¤©æ°”'].value_counts()
    valid_categories = weather_counts[weather_counts >= 2].index
    df = df[df['å¤©æ°”'].isin(valid_categories)]
    
    # æ·»åŠ æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
    df['3æ—¥å¹³å‡æ¸©åº¦'] = df['æœ€é«˜æ¸©åº¦'].rolling(3).mean()
    df['å‰æ—¥å¤©æ°”'] = df['å¤©æ°”'].shift(1)
    df = df.ffill().bfill()
    
    return df

def create_dataset(df, window_size=3):
    feature_cols = ['æœ€é«˜æ¸©åº¦', 'æœ€ä½æ¸©åº¦', 'é£åŠ›ç­‰çº§', 'æ¸©å·®', 
                   'æœˆä»½', 'å­£èŠ‚', '3æ—¥å¹³å‡æ¸©åº¦', 'å‰æ—¥å¤©æ°”']
    
    # åŠ¨æ€ç‰¹å¾ç¼–ç 
    df_encoded = pd.get_dummies(df[feature_cols], columns=['å‰æ—¥å¤©æ°”'])
    
    X, y = [], []
    for i in range(len(df) - window_size - 1):
        hist = df_encoded.iloc[i:i+window_size]
        label = df.iloc[i+window_size]['å¤©æ°”']
        X.append(hist.values.flatten())
        y.append(label)
    return np.array(X), np.array(y)

def train_model(X, y):
    # è°ƒæ•´æŠ½æ ·ç­–ç•¥
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.15,
            stratify=y,  # ä¿ç•™åˆ†å±‚æŠ½æ ·ä½†å·²ç¡®ä¿ç±»åˆ«æœ‰æ•ˆæ€§
            random_state=42
        )
    except ValueError:
        # å›é€€ç­–ç•¥ï¼šå½“åˆ†å±‚æŠ½æ ·å¤±è´¥æ—¶ä½¿ç”¨æ™®é€šæŠ½æ ·
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.15,
            random_state=42
        )
    
    # æ”¹è¿›æ ‡å‡†åŒ–æµç¨‹
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # ä¼˜åŒ–æ¨¡å‹å‚æ•°
    model = LGBMClassifier(
        n_estimators=150,
        learning_rate=0.2,
        max_depth=5,
        num_leaves=20,
        min_child_samples=5,
        class_weight='balanced',
        random_state=42,
        verbosity=-1
    )
    
    # æ·»åŠ æ ·æœ¬æƒé‡
    class_weights = {k: v for k, v in zip(*np.unique(y_train, return_counts=True))}
    sample_weights = np.array([class_weights[c] for c in y_train])
    
    model.fit(X_train_scaled, y_train, sample_weight=1/sample_weights)
    
    # è¾“å‡ºä¼˜åŒ–è¯„ä¼°
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    print(f"\nâœ… æ¨¡å‹å‡†ç¡®ç‡: {acc:.4f}")
    print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\n", classification_report(y_test, y_pred, zero_division=0))
    
    os.makedirs('./out', exist_ok=True)
    joblib.dump(model, './out/weather_clf_model.joblib')
    joblib.dump(scaler, './out/weather_scaler.joblib')
    joblib.dump(np.unique(y).tolist(), './out/weather_labels.joblib')
    return model, scaler

def predict_next_day(model, df, scaler):
    feature_cols = ['æœ€é«˜æ¸©åº¦', 'æœ€ä½æ¸©åº¦', 'é£åŠ›ç­‰çº§', 'æ¸©å·®', 
                   'æœˆä»½', 'å­£èŠ‚', '3æ—¥å¹³å‡æ¸©åº¦', 'å‰æ—¥å¤©æ°”']
    df_encoded = pd.get_dummies(df[feature_cols], columns=['å‰æ—¥å¤©æ°”'])
    
    # å¯¹é½ç‰¹å¾ç»´åº¦
    recent = df_encoded[-3:].values.flatten().reshape(1, -1)
    recent_scaled = scaler.transform(recent)
    
    pred = model.predict(recent_scaled)[0]
    print(f"\nğŸ“… é¢„æµ‹æ˜å¤©å¤©æ°”ï¼š{pred}")
    return pred

def main():
    df = load_and_preprocess()
    X, y = create_dataset(df)
    model, scaler = train_model(X, y)
    predict_next_day(model, df, scaler)

if __name__ == '__main__':
    main()
# âœ… æ¨¡å‹å‡†ç¡®ç‡: 0.1279

# ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:
#                precision    recall  f1-score   support

#           å…¶ä»–       0.56      0.05      0.10      7443
#           å¤šäº‘       0.44      0.02      0.03      7491
#            æ™´       0.29      0.30      0.29      3440
#            é›¨       0.08      0.76      0.14      1212
#            é›ª       0.01      0.44      0.03        93

#     accuracy                           0.13     19679
#    macro avg       0.27      0.31      0.12     19679
# weighted avg       0.43      0.13      0.11     19679


# ğŸ“… é¢„æµ‹æ˜å¤©å¤©æ°”ï¼šæ™´